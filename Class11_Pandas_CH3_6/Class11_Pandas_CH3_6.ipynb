{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation and Grouping\n",
    "\n",
    "### Planets Data\n",
    "* It gives info on planets that astronomers have discovered around other stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the planet data\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Aggregation in Pandas\n",
    "* For a pd Series the aggregates return a single value\n",
    "* For a pd DataFrame:\n",
    "    * **by default** the aggregates return results within each column\n",
    "    * by specifying the axis argument, aggregate within each row\n",
    "\n",
    "<img src = \"files/df_agg.png\" width = 550>\n",
    "<br>\n",
    "<img src = \"files/agg_para.png\" width = 550>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a pd Series the aggregates return a single value\n",
    "rng = np.random.RandomState(42)\n",
    "ser = pd.Series(rng.rand(5))\n",
    "ser.sum(), ser.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a pd DataFrame, by default \n",
    "# the aggregates return results within each column\n",
    "df = pd.DataFrame({'A' : rng.rand(5),\n",
    "                   'B' : rng.rand(5)})\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  df.describe(percentiles=None, include=None, exclude=None)\n",
    "\n",
    "<font color = red> 直接讲说明 </font>\n",
    "\n",
    "Signature: df.describe(percentiles=None, include=None, exclude=None)\n",
    "Docstring:\n",
    "Generates descriptive statistics that summarize the central tendency,\n",
    "dispersion and shape of a dataset's distribution, excluding\n",
    "``NaN`` values.\n",
    "\n",
    "Analyzes both numeric and object series, as well\n",
    "as ``DataFrame`` column sets of mixed data types. The output\n",
    "will vary depending on what is provided. Refer to the notes\n",
    "below for more detail.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "percentiles : list-like of numbers, optional\n",
    "    The percentiles to include in the output. All should\n",
    "    fall between 0 and 1. The default is\n",
    "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
    "    75th percentiles.\n",
    "\n",
    "\n",
    "include : 'all', list-like of dtypes or None (default), optional\n",
    "    A white list of data types to include in the result. Ignored\n",
    "    for ``Series``. Here are the options:\n",
    "\n",
    "    - 'all' : All columns of the input will be included in the output.\n",
    "    - A list-like of dtypes : Limits the results to the\n",
    "      provided data types.\n",
    "      To limit the result to numeric types submit\n",
    "      ``numpy.number``. To limit it instead to object columns submit\n",
    "      the ``numpy.object`` data type. Strings\n",
    "      can also be used in the style of\n",
    "      ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
    "      select pandas categorical columns, use ``'category'``\n",
    "    - None (default) : The result will include all numeric columns.\n",
    "exclude : list-like of dtypes or None (default), optional,\n",
    "    A black list of data types to omit from the result. Ignored\n",
    "    for ``Series``. Here are the options:\n",
    "\n",
    "    - A list-like of dtypes : Excludes the provided data types\n",
    "      from the result. To exclude numeric types submit\n",
    "      ``numpy.number``. To exclude object columns submit the data\n",
    "      type ``numpy.object``. Strings can also be used in the style of\n",
    "      ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
    "      exclude pandas categorical columns, use ``'category'``\n",
    "    - None (default) : The result will exclude nothing.\n",
    "    \n",
    "Notes\n",
    "-----\n",
    "For numeric data, the result's index will include ``count``,\n",
    "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
    "upper percentiles. By default the lower percentile is ``25`` and the\n",
    "upper percentile is ``75``. The ``50`` percentile is the\n",
    "same as the median.\n",
    "\n",
    "For object data (e.g. strings or timestamps), the result's index\n",
    "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
    "is the most common value. The ``freq`` is the most common value's\n",
    "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
    "\n",
    "If multiple object values have the highest count, then the\n",
    "``count`` and ``top`` results will be arbitrarily chosen from\n",
    "among those with the highest count.\n",
    "\n",
    "For mixed data types provided via a ``DataFrame``, the default is to\n",
    "return only an analysis of numeric columns. If the dataframe consists\n",
    "only of object and categorical data without any numeric columns, the\n",
    "default is to return an analysis of both the object and categorical\n",
    "columns. If ``include='all'`` is provided as an option, the result\n",
    "will include a union of attributes of each type.\n",
    "\n",
    "The `include` and `exclude` parameters can be used to limit\n",
    "which columns in a ``DataFrame`` are analyzed for the output.\n",
    "The parameters are ignored when analyzing a ``Series``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum(axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
    "df.product(axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
    "\n",
    "df.cumsum(axis=None, skipna=True, *args, **kwargs)\n",
    "df.cumprod(axis=None, skipna=True, *args, **kwargs)\n",
    "\n",
    "df.mean(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "df.median(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "df.std(axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
    "df.var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
    "df.skew(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "df.kurt(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
    "\n",
    "df.aggregate(func, axis=0, *args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"files/agg_met.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy: Split, Apply, Combine\n",
    "* aggregate conditionally on some label or index\n",
    "* implemented in **groupby** operation.\n",
    "* \"group by\" comes from a command in the SQL\n",
    "* More illuminative in terms of Rstats fame.\n",
    "\n",
    "#### Split, apply, combine\n",
    "* *split*: breaking up and grouping a df depending on the value of the specified key.\n",
    "* *apply*: computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "* *combine*: merge the results of these operations into an output array\n",
    "\n",
    "<img src = \"files/groupby_operation.PNG\" width = 450>\n",
    "\n",
    "<br>\n",
    "<font color = red>\n",
    "1. While we could certainly do this manually using some combination of th emasking, aggregation, and merging commands covered earlier, it's important to realize that *the intermediate splits do not need to explicitly instantiated\".\n",
    "2. Rather, the *GroupBy* can (often) do this in a single pass over the dta, updating the sum, mean, count, min or other aggregate for each group along the way.\n",
    "3. The power of the *GroupBy* is that it abstracts away these steps:\n",
    "    * the user need not think about *how* the computation is done under the hood, but rather thinks about the **operation as a whole.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df\n",
    "df = pd.DataFrame({'key':list('ABCABC'), \n",
    "                   'data': range(6)},\n",
    "                 columns = ['key', 'data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key') # Return a DataFrameGroupBy object\n",
    "                  # Does no actual computation until the aggregation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply an aggregate to produce a result\n",
    "# which performs appropirate apply/combine steps\n",
    "# You can apply virtually any common pd or np aggregation func\n",
    "df.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The GroupBy object\n",
    "* A very flexible abstraction.\n",
    "* treat it as if it's a collection of dfs\n",
    "* does the difficult things under the hood.\n",
    "* Perhaps, the most important operations are\n",
    "    * aggregate\n",
    "    * filter\n",
    "    * transform\n",
    "    * apply\n",
    "\n",
    "#### Column indexing\n",
    "* The GroupBy object supports column indexing as the df and returns a modified GroupBy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a particular Series group from the original DataFrame group\n",
    "# by reference to its column name.\n",
    "# no computation is done until we call some aggregate on the object\n",
    "planets.groupby('method')['orbital_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')['orbital_period'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration over groups\n",
    "* The GroupBy object supports direct iteration over the groups\n",
    "* returning each group as a *Series* or *DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (method, group) in planets.groupby('method'):\n",
    "    print(\"{0:30s} shape = {1}\".format(method, group.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (method, group) in planets.groupby('method'):\n",
    "    print(method, \"      \", group.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dispatch methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')['year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate, filter, transform, apply\n",
    "* GroupBy objects have aggregate(), filter(), transform(), and apply() methods\n",
    "* Efficiently implement a varietry of useful operations before combining the grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                  columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation\n",
    "* **aggregate()** method can take a string, a function, or a list thereof\n",
    "* Can pass a dictionary mapping column names to operations to be applied on that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate() method can take a string, a function, or a list thereof\n",
    "df.groupby('key').aggregate(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a dictionary mapping column names \n",
    "# to operations to be applied on that column\n",
    "df.groupby('key').aggregate({'data1' : 'min',\n",
    "                             'data2' : 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "* A **filtering** operation allows you to drop data based on the group properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby('key').std()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['key'] == 'A', 'data2'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation (???)\n",
    "* While aggregation must return a reduced version of the data, transfomration can return some transformed version of the full data to recombine.\n",
    "* For such a transformation, the output is the same shape as the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceter the data by subtracting the group-wise mean\n",
    "df.groupby('key').transform(lambda x: x - x.mean())\n",
    "\n",
    "# 看不懂，也查不到说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The apply() method\n",
    "* The **apply()** method lets you apply an arbitrary function to the group results\n",
    "    * THe function should take a DataFrame, and return either a Pandas object (e.g., DataFrame, Series) or a scalar;\n",
    "    * The combine operation will be tailored to the type of output returned.\n",
    "    * <font color = red> apply() within a GroupBy is quite flexible: the only criterion is that the function takes a DataFrame and returns a Pandas object or a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_data2(x):\n",
    "    # x is a df of gropu values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').apply(norm_by_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the split key\n",
    "\n",
    "##### A list, array, series, or index providing the grouping keys\n",
    "* The key can be any series or list with a length matching that of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0, 1, 0, 1, 2, 0]\n",
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(L).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['L'] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.groupby('L').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a more verbose way\n",
    "df2.groupby(df2['L']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dictionary or series mapping index to group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('key')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A':'vowel', 'B':'constant', 'C':'consonant'}\n",
    "df2.groupby(mapping).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Any Python function\n",
    "* Pass any Python function that will input the index value and output the group\n",
    "df2.groupby(str.lower).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass any Python function that will input the index value and output the group\n",
    "df2.groupby(str.lower).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  A list of valid keys\n",
    "* Any of the preceding key choices can be combined to group on a multi-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby([str.lower, mapping]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade = 10 * (planets['year']//10)\n",
    "decade = decade.astype(str) + 's'\n",
    "decade.name = 'decade'\n",
    "decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby(['method', decade]).sum()\n",
    "# decade here is a list of mapping index, same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "planets.groupby(['method', decade])['number'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "planets.groupby(['method', decade])['number'].sum().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
